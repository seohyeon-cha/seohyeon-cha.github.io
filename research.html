---
layout: page
title: Publication
---

<div class="project">
	<div class="project-thumb"><img src="/photos/framework-gefl.png" alt="GeFL system model"></div>
	<div class="project-content">
		<h3>Model-Agnostic Federated Learning with Generative Models</h3>
		<span style="color:#767676">Honggu Kang*</span>, <strong>Seohyeon Cha*</strong>, <span style="color:#767676">Jiwan Seo, and Joonhyuk Kang</span> (* Equal Contribution) <br> 
		In submission. 
		<div>
 		<a href="">paper</a> /
		<a href="https://honggkang.github.io/gefl/">project</a> / 
		<a id="show_cha2024_gefl" href="#show_cha2024_gefl" class="hide">abstract (+)</a>
		<a id="show_cha2024_gefl" href="#hide_cha2024_gefl" class="show">abstract (-)</a>
		<p class="details"> 
			Federated learning (FL) is a promising paradigm in distributed learning while preserving the privacy of users. However, the increasing size of recent models makes it unaffordable for a few users to encompass the model. It leads the users to adopt heterogeneous models based on their diverse computing capabilities and network bandwidth. Correspondingly, FL with heterogeneous models should be addressed, given that FL typically involves training a single global model. In this paper, we propose Generative Model-Aided Federated Learning (GeFL), incorporating a generative model which aggregates global knowledge across users of heterogeneous models. Our experiments on various classification tasks demonstrate the notable performance improvements of GeFL compared to baselines, as well as limitations in terms of privacy and scalability. To tackle these concerns, we introduce a novel framework, GeFL-F. It trains target networks aided by feature-generative models. We empirically demonstrate the consistent performance gains of GeFL-F, while proving better privacy preservation and robustness to a large number of clients.

		</p>
		</div>
	</div>
</div>

<div class="project">
	<div class="project-thumb"><img src="/photos/temp.png" alt="Empirical coverage and inefficiency of Bayesian CP"></div>
	<div class="project-content">
		<h3>On the Temperature of Bayesian Graph Neural Networks for Conformal Prediction</h3>
		<strong>Seohyeon Cha</strong>, <span style="color:#767676">Honggu Kang, and Joonhyuk Kang</span><br>
		NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023)
		<div>
		<a href="https://openreview.net/forum?id=Nrs8BA84br">paper</a> /
		<a id="show_cha2023_temp" href="#show_cha2023_temp" class="hide">abstract (+)</a>
		<a id="hide_cha2023_temp" href="#hide_cha2023_temp" class="show">abstract (-)</a>
		<p class="details">
			Accurate uncertainty quantification in graph neural networks (GNNs) is essential, especially in high-stakes domains where GNNs are frequently employed. Conformal prediction (CP) offers a promising framework for quantifying uncertainty by providing valid prediction sets for any black-box model. CP ensures formal probabilistic guarantees that a prediction set contains a true label with a desired probability. However, the size of prediction sets, known as inefficiency, is influenced by the underlying model and data generating process. On the other hand, Bayesian learning also provides a credible region based on the estimated posterior distribution, but this region is well-calibrated only when the model is correctly specified. Building on a recent work that introduced a scaling parameter for constructing valid credible regions from posterior estimate, our study explores the advantages of incorporating a temperature parameter into Bayesian GNNs within CP framework. We empirically demonstrate the existence of temperatures that result in more efficient prediction sets. Furthermore, we conduct an analysis to identify the factors contributing to inefficiency and offer valuable insights into the relationship between CP performance and model calibration. 
		</p>
		</div>
	</div>
</div>

<div class="project">
	<div class="project-thumb"><img src="/photos/nefl_frame.png" alt="stroke subject demonstrating hand closing and opening while wearing device"></div>
	<div class="project-content">
		<h3>NeFL: Nested Model Scaling for Federated Learning with System Heterogeneous Clients</h3>
		<span style="color:#767676">Honggu Kang, </span><strong>Seohyeon Cha</strong><span style="color:#767676">, Jinwoo Shin, Jongmyeong Lee, and Joonhyuk Kang</span><br>
		In submission.  
		<div>
		<a href="https://arxiv.org/abs/2308.07761">paper</a> / 
		<a href="https://honggkang.github.io/nefl/">project</a> / 	
		<a id="show_cha2023_nefl" href="#show_cha2023_nefl" class="hide">abstract (+)</a>
		<a id="hide_cha2023_nefl" href="#hide_cha2023_nefl" class="show">abstract (-)</a>
		<p class="details">
			Federated learning (FL) enables distributed training while preserving data privacy, but stragglers—slow or incapable clients—can significantly slow down the total training time and degrade performance. To mitigate the impact of stragglers, system heterogeneity, including heterogeneous computing and network bandwidth, has been addressed. While previous studies have addressed system heterogeneity by splitting models into submodels, they offer limited flexibility in model architecture design, without considering potential inconsistencies arising from training multiple submodel architectures. We propose <i>nested federated learning (NeFL)</i>, a generalized framework that efficiently divides deep neural networks into submodels using both depthwise and widthwise scaling. NeFL interprets forward propagation as solving ordinary differential equations (ODEs) with adaptive step sizes, allowing for dynamic submodel architectures. To address the inconsistency arising from training multiple submodel architectures, NeFL decouples a subset of parameters from those being trained for each submodel. An averaging method is proposed to handle these decoupled parameters during aggregation. NeFL enables resource-constrained devices to effectively participate in the FL pipeline, facilitating larger datasets for model training. Experiments demonstrate that NeFL achieves performance gain, especially for the worst-case submodel compared to baseline approaches. Furthermore, NeFL aligns with recent advances in FL, such as leveraging pre-trained models and accounting for statistical heterogeneity.
		</p>
		</div>
	</div>
</div>


<div class="project">
	<div class="project-thumb"><img src="/photos/its.png" alt="stroke subject demonstrating hand closing and opening while wearing device"></div>
	<div class="project-content">
		<h3>Intelligent Surface-aided Transmit-array Antenna in mmWave Communication System with Historical Channel Observation</h3>
		<strong>Seohyeon Cha</strong><span style="color:#767676">, Sanghyuk Kim, Jiwan Seo, and Joonhyuk Kang</span><br>
		In IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia), 2022. 
		<div>
		<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y424CngAAAAJ&citation_for_view=y424CngAAAAJ:9yKSN-GCB0IC">paper</a> / 
		<a id="show_cha2022_its" href="#show_cha2022_its" class="hide">abstract (+)</a>
		<a id="hide_cha2022_its" href="#hide_cha2022_its" class="show">abstract (-)</a>
		<p class="details">
			In this paper, we study an intelligent surface-aided transmit-array antenna architecture which deploys intelligent transmitting surface (ITS) near the active antenna in mmWave downlink communication system. We aim to maximize the average achievable rate at the user by optimizing the phase shift matrix of ITS. To overcome the difficulty of acquiring channel state information (CSI), we propose a stochastic gradient descent (SGD)-based algorithm that requires only historical channel observations. Simulation results show that our proposed scheme with single active antenna and ITS outperforms conventional MISO system.
		</p>
		</div>
	</div>
</div>


<footer class="footer" style="vertical-align:bottom;text-align:left;margin-top:50px;">
	<hr>
    <div>kaitjgus<span style="font-size:9pt;padding-right:1px;padding-left:1px;"><i alt="at sign" class="fas fa-at"></i></span>kaist.ac.kr</div>
    <div>Last Updated:&nbsp; <time datetime="{{ site.time | date_to_xmlschema }}">{{ site.time | date: '%m-%d-%Y' }}</time></div>    
</footer>
